{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0285d569",
   "metadata": {},
   "source": [
    "## Titanic Shipwreck\n",
    "\n",
    "### Objective: Use Machine Learning to create a model that can predict which passengers survived the Titanic shipwreck.\n",
    "### This is a ML competition running on Kaggle. For more info: https://www.kaggle.com/c/titanic\n",
    "### Huge thanks to Aurelien Geron, whom I consider as my mentor. I have used many ideas from your teachings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc8ba9a",
   "metadata": {},
   "source": [
    "#### Loading necessary data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ff21cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_train = pd.read_csv('titanic_training_data')\n",
    "df_test = pd.read_csv('titanic_test_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a65064",
   "metadata": {},
   "source": [
    "#### We'll make a copy of training DF so that we don't accidentally make changes to original DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "600c97be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df_train.copy()\n",
    "test_df = df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7827e6",
   "metadata": {},
   "source": [
    "#### Let's explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cabb3f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82a8b8de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d11850d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea54a97",
   "metadata": {},
   "source": [
    "#### Few points to notice:\n",
    "#### 1. 'PassengerId' column is same as index, we can either drop this column or set it as index.\n",
    "#### 2. There are missing values in 'Age' (20%), 'Cabin' (77%) and 'Embarked' (0.002%) columns. With so many missing values, we will need to decide how to deal with these columns. Will they provide any value? What is a better option - dropping these columns with missing values or replacing missing values?\n",
    "#### 2. There are 4 numerical columns ('Age', 'SibSp', 'Parch', 'Fare') and 5 categorical columns ('Pclass', 'Name', 'Sex', 'Ticket', 'Cabin', 'Embarked'). We will make pipelines to deal with them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed1f5a8",
   "metadata": {},
   "source": [
    "#### But before that let's quickly check which features are important. Dropping 'PassengerId',  'Name', 'Ticket', 'Cabin' columns, changing categorical columns to numerical and filling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9a424f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_feat_imp = train_df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "train_df_feat_imp['Sex'] = train_df_feat_imp['Sex'].map({'female': 0, 'male': 1})\n",
    "train_df_feat_imp['Embarked'] = train_df_feat_imp['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
    "\n",
    "train_df_feat_imp['Age'] = train_df_feat_imp['Age'].fillna(train_df_feat_imp['Age'].median())\n",
    "train_df_feat_imp['Embarked'] = train_df_feat_imp['Embarked'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fb0adc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
       "0         0       3    1  22.0      1      0   7.2500       0.0\n",
       "1         1       1    0  38.0      1      0  71.2833       1.0\n",
       "2         1       3    0  26.0      0      0   7.9250       0.0\n",
       "3         1       1    0  35.0      1      0  53.1000       0.0\n",
       "4         0       3    1  35.0      0      0   8.0500       0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_feat_imp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43749b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df_feat_imp.drop(['Survived'], axis=1)\n",
    "y_train = train_df_feat_imp['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ced72a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass 0.09\n",
      "Sex 0.26\n",
      "Age 0.26\n",
      "SibSp 0.05\n",
      "Parch 0.04\n",
      "Fare 0.27\n",
      "Embarked 0.03\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "for name, score in zip(X_train.columns, rnd_clf.feature_importances_):\n",
    "    print(name, round(score, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392656ba",
   "metadata": {},
   "source": [
    "#### It seems that most important features are 'Sex', 'Age' and 'Fare'. We can try and test different ML models with these 3 attributes and check how good the results are."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ddaa1e",
   "metadata": {},
   "source": [
    "#### Going back to our dataset from before, we will now split the dataset into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b035ea8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ffba4c",
   "metadata": {},
   "source": [
    "#### Since we are keeping only 3 attributes, namely 'Age', 'Sex' and 'Fare', we will drop the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1c64652",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8298eaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Sex'] = train_df['Sex'].map({'female': 0, 'male': 1})\n",
    "train_df['Age'] = train_df['Age'].fillna(train_df['Age'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "567a785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3_features = train_df[['Sex', 'Age', 'Fare']]\n",
    "y_3_features = train_df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0fa3e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3_features, X_test_3_features, y_train_3_features, y_test_3_features = X_3_features[:700], X_3_features[700:], y_3_features[:700], y_3_features[700:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8392853c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>0.647587</td>\n",
       "      <td>29.361582</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>0.477990</td>\n",
       "      <td>13.019697</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Sex         Age  \\\n",
       "count   891.000000  891.000000  891.000000  891.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642    0.647587   29.361582   \n",
       "std     257.353842    0.486592    0.836071    0.477990   13.019697   \n",
       "min       1.000000    0.000000    1.000000    0.000000    0.420000   \n",
       "25%     223.500000    0.000000    2.000000    0.000000   22.000000   \n",
       "50%     446.000000    0.000000    3.000000    1.000000   28.000000   \n",
       "75%     668.500000    1.000000    3.000000    1.000000   35.000000   \n",
       "max     891.000000    1.000000    3.000000    1.000000   80.000000   \n",
       "\n",
       "            SibSp       Parch        Fare  \n",
       "count  891.000000  891.000000  891.000000  \n",
       "mean     0.523008    0.381594   32.204208  \n",
       "std      1.102743    0.806057   49.693429  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    7.910400  \n",
       "50%      0.000000    0.000000   14.454200  \n",
       "75%      1.000000    0.000000   31.000000  \n",
       "max      8.000000    6.000000  512.329200  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ed2979",
   "metadata": {},
   "source": [
    "#### Data indicates very low survival rate, mere 38%. This implies that accuracy as an evaluation metric should suffice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb59184",
   "metadata": {},
   "source": [
    "### Testing different ML Models\n",
    "\n",
    "#### Let's start with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6174a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79487179, 0.78540773, 0.75536481])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "log_reg_3_features = LogisticRegression()\n",
    "log_reg_3_features.fit(X_train_3_features, y_train_3_features)\n",
    "\n",
    "cross_val_score(log_reg_3_features, X_train_3_features, y_train_3_features, cv=3, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b471adbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[358,  71],\n",
       "       [ 84, 187]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_3_features = cross_val_predict(log_reg_3_features, X_train_3_features, y_train_3_features, cv=3)\n",
    "confusion_matrix(y_train_3_features, y_pred_3_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "065c79f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy  0.7785714285714286\n",
      "precision  0.7248062015503876\n",
      "recall  0.6900369003690037\n",
      "f1 score  0.7069943289224953\n"
     ]
    }
   ],
   "source": [
    "print('accuracy ', accuracy_score(y_train_3_features, y_pred_3_features))\n",
    "print('precision ', precision_score(y_train_3_features, y_pred_3_features))\n",
    "print('recall ', recall_score(y_train_3_features, y_pred_3_features))\n",
    "print('f1 score ', f1_score(y_train_3_features, y_pred_3_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee1b7eb",
   "metadata": {},
   "source": [
    "#### We are achieving the accuracy of 77%. Now let's try and see how other ML models perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b4a0557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_clf = 0.8\n",
      "sgd_clf = 0.72\n",
      "svc_clf = 0.71\n",
      "tree_clf = 0.79\n",
      "rnd_clf = 0.81\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "\n",
    "voting_clf = VotingClassifier(estimators= [('log_clf', LogisticRegression(random_state=42)),\n",
    "                                           ('sgd_clf', SGDClassifier(random_state=42)),\n",
    "                                           ('svc_clf', SVC(random_state=42)), \n",
    "                                           ('tree_clf', DecisionTreeClassifier(max_depth=2, random_state=42)),\n",
    "                                           ('rnd_clf', RandomForestClassifier(random_state=42))\n",
    "                                          ], voting = 'hard')\n",
    "\n",
    "voting_clf.fit(X_train_3_features, y_train_3_features)\n",
    "\n",
    "for name, clf in voting_clf.named_estimators_.items():\n",
    "    print(name, '=', round(clf.score(X_test_3_features, y_test_3_features), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ab8951",
   "metadata": {},
   "source": [
    "#### It seems our best bet with 3 selected features is Random Forest Classifier. Let's check the performance of voting_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3e8ca35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(voting_clf.score(X_test_3_features, y_test_3_features), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccbee81",
   "metadata": {},
   "source": [
    "#### Looks like voting_clf is not performing as well as we hoped. How about other methods like bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14b229cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(RandomForestClassifier(), n_estimators=500, max_samples=100, \n",
    "                            n_jobs=-1, random_state=42, bootstrap=True)\n",
    "\n",
    "bag_clf.fit(X_train_3_features, y_train_3_features)\n",
    "round(bag_clf.score(X_test_3_features, y_test_3_features), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46be17f",
   "metadata": {},
   "source": [
    "#### The highest score we achieved is still 81%, even with Bagging method. How about if we use a different classifier in bagging method. Let's try Decision tree and see if we get a better result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56cd9278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=500, max_samples=100, \n",
    "                            n_jobs=-1, random_state=42, bootstrap=True)\n",
    "\n",
    "bag_clf.fit(X_train_3_features, y_train_3_features)\n",
    "round(bag_clf.score(X_test_3_features, y_test_3_features), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c80ada",
   "metadata": {},
   "source": [
    "#### Bagging methos with Decision tree classifier gives a slightly better result. Does AdaBoost Classifier performs any better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6efb40b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=30,\n",
    "                            learning_rate=0.5, random_state=42)\n",
    "\n",
    "ada_clf.fit(X_train_3_features, y_train_3_features)\n",
    "round(ada_clf.score(X_test_3_features, y_test_3_features), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba30404",
   "metadata": {},
   "source": [
    "#### So far our best option is Bagging Classifier with Decision Tree. Its giving us 82% score. So we select Bagging Classifier as our preferred model and see if we can improve the score any further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "954f1d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78632479, 0.80257511, 0.75107296])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(bag_clf, X_train_3_features, y_train_3_features, cv=3, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2538caad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[358,  71],\n",
       "       [ 83, 188]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_bag = cross_val_predict(bag_clf, X_train_3_features, y_train_3_features, cv=3)\n",
    "\n",
    "confusion_matrix(y_train_3_features, y_pred_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c14ff5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.78\n",
      "Precision =  0.73\n",
      "Recall =  0.69\n",
      "f1 score =  0.71\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy = ', round(accuracy_score(y_train_3_features, y_pred_bag), 2))\n",
    "print('Precision = ', round(precision_score(y_train_3_features, y_pred_bag), 2))\n",
    "print('Recall = ', round(recall_score(y_train_3_features, y_pred_bag), 2))\n",
    "print('f1 score = ', round(f1_score(y_train_3_features, y_pred_bag), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418bbffb",
   "metadata": {},
   "source": [
    "#### There is a dip in accuracy result. This model is under fitting on training set and giving better results on test results. Let's change our approach and start afresh with a new approach. Let's use more features, create pipelines and apply different ML models to see if results are any better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9aa052ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "num_pipe = Pipeline([('imputer', SimpleImputer(strategy='median')),\n",
    "                     ('scaler', StandardScaler())                    \n",
    "                    ])\n",
    "\n",
    "cat_pipe = Pipeline([('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                     ('one hot', OneHotEncoder())\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae3fb75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_attribs = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "cat_attribs = ['Pclass', 'Sex', 'Embarked']\n",
    "\n",
    "final_pipe = ColumnTransformer([('num', num_pipe, num_attribs),\n",
    "                                ('cat', cat_pipe, cat_attribs)\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ce46a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.56573646,  0.43279337, -0.47367361, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.66386103,  0.43279337, -0.47367361, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.25833709, -0.4745452 , -0.47367361, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       ...,\n",
       "       [-0.1046374 ,  0.43279337,  2.00893337, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.25833709, -0.4745452 , -0.47367361, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.20276197, -0.4745452 , -0.47367361, ...,  0.        ,\n",
       "         1.        ,  0.        ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_pipe = df_train.copy()\n",
    "\n",
    "X_train_pipe = final_pipe.fit_transform(train_df_pipe[num_attribs + cat_attribs])\n",
    "y_train_pipe = train_df_pipe['Survived']\n",
    "X_test = final_pipe.transform(test_df[num_attribs + cat_attribs])\n",
    "\n",
    "X_train_pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb438bf7",
   "metadata": {},
   "source": [
    "#### Final pipeline is ready. Let's start testing different ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f713f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7991260923845193"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_pipe, y_train_pipe)\n",
    "\n",
    "log_reg_score = cross_val_score(log_reg, X_train_pipe, y_train_pipe, cv=10)\n",
    "log_reg_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "efb41b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_clf = 0.81\n",
      "sgd_clf = 0.81\n",
      "svc_clf = 0.84\n",
      "tree_clf = 0.8\n",
      "rnd_clf = 0.98\n"
     ]
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(estimators= [('log_clf', LogisticRegression(random_state=42)),\n",
    "                                           ('sgd_clf', SGDClassifier(random_state=42)),\n",
    "                                           ('svc_clf', SVC(random_state=42)), \n",
    "                                           ('tree_clf', DecisionTreeClassifier(max_depth=2, random_state=42)),\n",
    "                                           ('rnd_clf', RandomForestClassifier(random_state=42))\n",
    "                                          ], voting = 'hard')\n",
    "\n",
    "voting_clf.fit(X_train_pipe, y_train_pipe)\n",
    "\n",
    "for name, clf in voting_clf.named_estimators_.items():\n",
    "    print(name, '=', round(clf.score(X_train_pipe, y_train_pipe), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779f2cc9",
   "metadata": {},
   "source": [
    "#### 98% with Random Forest Classifier? Is it true or something has gone wrong? Let's checkits performance on its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f427bf1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8036828963795255"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clf_pipe = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "rnd_clf_pipe.fit(X_train_pipe, y_train_pipe)\n",
    "\n",
    "rnd_clf_score = cross_val_score(rnd_clf_pipe, X_train_pipe, y_train_pipe, cv=10)\n",
    "rnd_clf_score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415d6eed",
   "metadata": {},
   "source": [
    "#### 80% score seems more realistic. Let's try and find the scores of different models independently and not as a part of ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7cec196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7856554307116105"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train_pipe, y_train_pipe)\n",
    "sgd_clf_score = cross_val_score(sgd_clf, X_train_pipe, y_train_pipe, cv=10)\n",
    "sgd_clf_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19e01026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[456 117]\n",
      " [ 93 225]]\n",
      "accuracy = 0.76\n"
     ]
    }
   ],
   "source": [
    "y_pred_sgd_clf = cross_val_predict(sgd_clf, X_train_pipe, y_train_pipe, cv=3)\n",
    "\n",
    "cm_sgd_clf = confusion_matrix(y_pred_sgd_clf, y_train_pipe)\n",
    "print(cm_sgd_clf)\n",
    "print('accuracy =', round(accuracy_score(y_pred_sgd_clf, y_train_pipe), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7502fdf5",
   "metadata": {},
   "source": [
    "#### SGD Classifier scores are less than Random Forest Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "14168625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8249313358302123"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_clf = SVC(gamma='auto', random_state=42)\n",
    "svc_clf.fit(X_train_pipe, y_train_pipe)\n",
    "svc_clf_score = cross_val_score(svc_clf, X_train_pipe, y_train_pipe, cv=10)\n",
    "svc_clf_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8fc4a2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[491  98]\n",
      " [ 58 244]]\n",
      "accuracy = 0.82\n"
     ]
    }
   ],
   "source": [
    "y_pred_svc_clf = cross_val_predict(svc_clf, X_train_pipe, y_train_pipe, cv=3)\n",
    "\n",
    "cm_svc_clf = confusion_matrix(y_pred_svc_clf, y_train_pipe)\n",
    "print(cm_svc_clf)\n",
    "print('accuracy =', round(accuracy_score(y_pred_svc_clf, y_train_pipe), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b90f40",
   "metadata": {},
   "source": [
    "#### Support Vector Classifier seems like a better model with 82% accuracy and only 58 False Positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d5564d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7688764044943821"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "tree_clf.fit(X_train_pipe, y_train_pipe)\n",
    "tree_clf_score = cross_val_score(tree_clf, X_train_pipe, y_train_pipe, cv=10)\n",
    "tree_clf_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6c4121f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[488  61]\n",
      " [136 206]]\n",
      "accuracy = 0.78\n"
     ]
    }
   ],
   "source": [
    "y_pred_tree_clf = cross_val_predict(tree_clf, X_train_pipe, y_train_pipe, cv=3)\n",
    "\n",
    "cm_tree_clf = confusion_matrix(y_train_pipe, y_pred_tree_clf)\n",
    "print(cm_tree_clf)\n",
    "print('accuracy =', round(accuracy_score(y_pred_tree_clf, y_train_pipe), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e377aae",
   "metadata": {},
   "source": [
    "#### After testing various ML models, our choice of model seems to be Support Vector Classifier with highest score and least False Positives. We will use this model to predict on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ac27c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svc_clf = svc_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83985c3f",
   "metadata": {},
   "source": [
    "#### This prediction result can now be converted in csv file and uploaded on kaggle platform. Later on we will try deep learning models to see if we achieve even better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4177843e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
